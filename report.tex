\documentclass[conference,a4paper]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
%Template version as of 6/27/2024

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{tikz}
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{multirow}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

% Command to include a center figure
\newcommand{\centerfigure}[2]{
    \begin{figure}[htbp]
        \centering
        \includegraphics[width=0.9\linewidth]{figures/#1.png}
        \caption{#2}
        \label{fig:#1}
    \end{figure}
}

\newcommand{\centertable}[2]{
    \begin{table}[htbp]
        \centering
        \caption{#2}
        \input{figures/#1.tex}
        \label{tab:#1}
    \end{table}
}

\setlength{\abovedisplayskip}{1pt}
\setlength{\belowdisplayskip}{0pt}
\begin{document}

\title{AIML 425 Assignment 4 %\\
%{\footnotesize \textsuperscript{*}Note: Sub-titles are not captured for https://ieeexplore.ieee.org  and
%should not be used}
%\thanks{Identify applicable funding agency here. If none, delete this.}
}

\author{\IEEEauthorblockN{James Thompson}
%\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{Victoria University of Wellington}\\
%City, Country \\
300680096}

% Figure example import part is the htbp
% \begin{figure}[htbp]
% \centerline{\includegraphics{fig1.png}}
% \caption{Example of a figure caption.}
% \label{fig}
% \end{figure}

\maketitle

\section{Introduction}

This document reports the implementation and results of Assignment 4. I implement Stochastic Differential Equations and Ordinary Differential Equation models. THe SDE model is a score based generative model to learn a mapping from Gaussian noise to dog images. The ODE model is a normalizing flow model that learns a mapping from Gaussian to dogs and cats to dogs.

\section{Theory}

I will be looking at two models, a Stochastic Differential Equation (SDE) model and an Ordinary Differential Equation (ODE) model. Both models are generative models that learn a mapping from one distribution to another. The key difference being that the SDE model is score based and stochastic in generation while the ODE model is a normalizing flow model that is deterministic in generation.

\subsection{Flows}

\subsection{Stochastic Differential Equations}


\subsection{Ordinary Differential Equations}

\subsection{Performance comparison}

The end objective of both models is to learn how to take data from one distribution to another iteratively. The loss shows us the difference between the flows. However to understand the performance we really want to know how well it can generate samples. A simple and effective measure is Mean Maximum Discrepancy (MMD) \cite{grettonKernelMethodTwoSample2008} which allows us to compare the generated samples to the real target distribution. The MMD is a measure of the distance between two distributions based on samples from each distribution. It is defined as

\begin{align}
    \text{MMD}^2(P, Q) &= \mathbb{E}[k(x, x')] + \mathbb{E}[k(y, y')] - 2\mathbb{E}[k(x, y)]\\
    \text{where } k(x, y) &= \exp\left(-\frac{\|x - y\|^2}{2\sigma^2}\right)\\
    \text{and } &x, x' \sim P, \quad y, y' \sim Q 
\end{align}

The only parameter in this is the kernel bandwidth $\sigma$. The higher the sigma the smoother the kernel so focuses on global differences, where lower sigma focuses on local differences.

Other metrics to understand the performance can be learning efficiency and sample efficiency. This means that we can compare how many samples it takes to learn as well as how much compute time it takes to learn. This can be measured in terms of number of epochs or wall clock time.

\section{Experiments}


\section{Conclusion}


\newpage
\section*{Statement}

The code and report of the Assignment was solely completed by myself (Thompson James). The complete source code can be found here \url{https://gitea.james-server.duckdns.org/james/AIML425\_assignment\_4}, with a link to a colab notebook found here: \url{https://colab.research.google.com/github/1jamesthompson1/AIML425_assignment_4/blob/main/main.ipynb}. A complete run through of the notebook takes about 10 minutes on a GPU enabled machine.

I have kept the appendix as concise as possible, however the code is setup to produce many more figures and tables that can be used to understand the models. Most of these figures have been generated and stored in the `figures` folder.

I completed my work using the following tools:
\begin{itemize}
    \item \textbf{Jupyter Notebook \cite{Kluyver2016jupyter} and JupyterText \cite{woutsMwoutsJupytext2025}:} For interactive development and hosting.
    \item \textbf{\LaTeX}: For writing the report.
    \item \textbf{VSCode \cite{MicrosoftVscode2025}:} As IDE, with Copilot to help with plotting and debugging.
    \item \textbf{JAX \cite{jax2018github} and Flax \cite{flax2020github}:} For implementing the neural network and training logic.
    \item \textbf{Matplotlib\cite{Hunter:2007} and Pandas\cite{thepandasdevelopmentteamPandasdevPandasPandas}:} For data visualization and management.
\end{itemize}


\bibliographystyle{IEEEtran}
\bibliography{references}

\appendix

\section{Model experiments}


\subsection{Setup}
\begin{table}
    \caption{Hyperparameters used for each model}
    \label{tab:hyp}
    \centering
    \begin{tabular}{lccc}
        \toprule
        Hyperparameter & SDE & ODE (Gauss to Dog) & ODE (Cat to Dog) \\
        \midrule
        Learning Rate & \multicolumn{2}{c}{0.0001} \\
        Minibatch Size & 512 & \multicolumn{2}{c}{256} \\
        Hidden Dims & 512 & \multicolumn{2}{c}{256}\\
        Hidden Layers & 4 & \multicolumn{2}{c}{3} \\
        Num Epochs & 500 & \multicolumn{2}{c}{200}\\
        Optimizer & \multicolumn{3}{c}{Adam} \\
        Loss Function & \multicolumn{3}{c}{MSE} \\
        \midrule
        \bottomrule
    \end{tabular}
\end{table}

\subsection{Results}
The models were trained using the hyperparameters in Table \ref{tab:hyp}. They were trained on a RTX A5000 GPU with a Xeon(R) Gold 6128 CPU. 
\begin{table}
    \caption{Training results}
    \label{tab:mmd}
    \centering
    \begin{tabular}{lccc}
        \toprule
        Result & SDE & ODE (Gauss to Dog) & ODE (Cat to Dog) \\
        Runtime (seconds) & ? & ? & ? \\
        MMD & ? & ? & ? \\
        Best validation loss & ? & ? & ? \\
        \midrule
        \bottomrule
    \end{tabular}
\end{table}

\section{Figures}



\end{document}
